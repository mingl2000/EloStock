import tensorflow as tf
import numpy as np
import yfinance as yf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
import random
import os

def plot_train_history(history, title):
  loss = history.history['loss']
  val_loss = history.history['val_loss']

  epochs = range(len(loss))

  plt.figure()
  plt.xscale('log')
  plt.plot(epochs, loss, 'b', label='Training loss')
  plt.plot(epochs, val_loss, 'r', label='Validation loss')
  plt.title(title)
  plt.legend()
  plt.savefig('/mnt/d/PriProjects/EloStock/tensorflow_history.png')
  #plt.show()

def set_random_seed():
    seed = 42
    tf.random.set_seed(seed)
    np.random.seed(seed)
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)

# Elo functions
def calculate_expected_score(rating_a, rating_b):
    """Calculate the expected score of stock A against stock B."""
    return 1 / (1 + 10 ** ((rating_b - rating_a) / 400))

def update_elo_ratings(stocks, returns, k=32):
    """Update Elo ratings based on returns with magnitude weighting."""
    updated_ratings = stocks.copy()
    stock_list = list(returns.keys())
    
    for i in range(len(stock_list)):
        for j in range(i + 1, len(stock_list)):
            stock_a = stock_list[i]
            stock_b = stock_list[j]
            
            # Get returns for both stocks
            return_a = returns[stock_a]
            return_b = returns[stock_b]
            
            # Calculate actual outcomes with magnitude
            actual_a = max(0, min(1, (return_a - return_b) / (abs(return_a) + abs(return_b) + 1e-10)))
            actual_b = 1 - actual_a
            
            # Current ratings
            rating_a = stocks[stock_a]
            rating_b = stocks[stock_b]
            
            # Expected scores
            expected_a = calculate_expected_score(rating_a, rating_b)
            expected_b = calculate_expected_score(rating_b, rating_a)
            
            # Update ratings with magnitude-weighted outcomes
            updated_ratings[stock_a] += k * (actual_a - expected_a)
            updated_ratings[stock_b] += k * (actual_b - expected_b)
    
    return updated_ratings

# Fetch stock data
def fetch_stock_data(tickers, start_date, end_date):
    """Fetch historical stock data from Yahoo Finance."""
    data = yf.download(tickers, start=start_date, end=end_date)['Adj Close']
    data.dropna(inplace=True)
    
    daily_returns = data.pct_change().iloc[1:]  # Calculate daily returns
    return data, daily_returns

# Prepare dataset
def prepare_dataset(tickers, start_date, end_date):
    """Prepare features and target (Elo ratings) for machine learning."""
    data, returns = fetch_stock_data(tickers, start_date, end_date)
    stock_ratings = {ticker: 1500 for ticker in tickers}  # Initial Elo ratings
    
    # Calculate Elo ratings for each day
    elo_ratings = []
    dates = []
    for date, row in returns.iterrows():
        daily_returns = row.to_dict()
        stock_ratings = update_elo_ratings(stock_ratings, daily_returns)
        elo_ratings.append(list(stock_ratings.values()))
        dates.append(date)
    
    features = returns.values[1:]  # Daily returns as features
    target = np.array(elo_ratings[1:])  # Elo ratings as the target variable
    return features, target, dates, data

# TensorFlow model
def build_model(input_shape):
    """Build and compile a TensorFlow model."""
    model = tf.keras.Sequential([ 
        tf.keras.layers.Dense(128, activation='relu', input_shape=(input_shape,)),
        tf.keras.layers.Dropout(0.3),  # Dropout layer to prevent overfitting
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(32, activation='relu'),
        tf.keras.layers.Dense(len(tickers))  # Output one value per stock
    ])
    
    # Experiment with a lower learning rate and a different optimizer (RMSprop)
    model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0005), loss='mse', metrics=['mae'])
    return model
def dynamic_lr(epoch, lr):
    if (epoch//10) < 2:
        return lr  # Keep the initial learning rate
    return lr * 0.5  # Reduce by 50%

# Wrap the custom scheduler in a callback


def training(checkpoint_path):
    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
        filepath=checkpoint_path,
        monitor="val_loss",
        save_best_only=True,
        mode="max"  # 'max' for maximizing the monitored metric
    )
    # Build and train the model
    model = build_model(X_train.shape[1])
    lr_scheduler = tf.keras.callbacks.LearningRateScheduler(dynamic_lr)
    history =model.fit(X_train, y_train, epochs=100, batch_size=16, validation_split=0.1, verbose=1, callbacks=[lr_scheduler, checkpoint_callback])
    plot_train_history(history,'multi Step Training and validation loss')
# Main script
if __name__ == "__main__":
    set_random_seed()
    tickers = ["AAPL", "MSFT", "GOOG", "AMZN", "TSLA"]
    # kechuang50
    tickers = ["689009.SS","688981.SS","688819.SS","688777.SS","688728.SS",            
            "688617.SS","688599.SS","688561.SS","688538.SS",
            "688349.SS","688303.SS","688301.SS","688297.SS","688295.SS",
            "688220.SS","688188.SS","688187.SS","688180.SS","688169.SS",
            "688126.SS","688122.SS","688120.SS","688114.SS","688111.SS",
            "688099.SS","688082.SS","688072.SS","688065.SS","688047.SS",
            "688041.SS","688036.SS","688012.SS","688009.SS","688008.SS",
            "688271.SS","688256.SS","688234.SS","688223.SS",
            "688396.SS","688385.SS","688375.SS",
            "688525.SS","688521.SS","688475.SS"]
    #HS300
    tickers = "000001.SZ,000002.SZ,000063.SZ,000100.SZ,000157.SZ,000166.SZ,000301.SZ,000333.SZ,000338.SZ,000408.SZ,000425.SZ,000538.SZ,000568.SZ,000596.SZ,000617.SZ,000625.SZ,000630.SZ,000651.SZ,000661.SZ,000708.SZ,000725.SZ,000768.SZ,000776.SZ,000786.SZ,000792.SZ,000800.SZ,000807.SZ,000858.SZ,000876.SZ,000895.SZ,000938.SZ,000963.SZ,000975.SZ,000977.SZ,000983.SZ,000999.SZ,001289.SZ,001965.SZ,001979.SZ,002001.SZ,002007.SZ,002027.SZ,002028.SZ,002049.SZ,002050.SZ,002074.SZ,002129.SZ,002142.SZ,002179.SZ,002180.SZ,002230.SZ,002236.SZ,002241.SZ,002252.SZ,002271.SZ,002304.SZ,002311.SZ,002352.SZ,002371.SZ,002415.SZ,002422.SZ,002459.SZ,002460.SZ,002463.SZ,002466.SZ,002475.SZ,002493.SZ,002555.SZ,002594.SZ,002601.SZ,002648.SZ,002709.SZ,002714.SZ,002736.SZ,002812.SZ,002916.SZ,002920.SZ,002938.SZ,003816.SZ,300014.SZ,300015.SZ,300033.SZ,300059.SZ,300122.SZ,300124.SZ,300274.SZ,300308.SZ,300316.SZ,300347.SZ,300394.SZ,300408.SZ,300413.SZ,300418.SZ,300433.SZ,300442.SZ,300450.SZ,300498.SZ,300502.SZ,300628.SZ,300661.SZ,300750.SZ,300759.SZ,300760.SZ,300782.SZ,300832.SZ,300896.SZ,300979.SZ,300999.SZ,301269.SZ,600000.SS,600009.SS,600010.SS,600011.SS,600015.SS,600016.SS,600018.SS,600019.SS,600023.SS,600025.SS,600026.SS,600027.SS,600028.SS,600029.SS,600030.SS,600031.SS,600036.SS,600039.SS,600048.SS,600050.SS,600061.SS,600066.SS,600085.SS,600089.SS,600104.SS,600111.SS,600115.SS,600150.SS,600160.SS,600161.SS,600176.SS,600183.SS,600188.SS,600196.SS,600219.SS,600233.SS,600276.SS,600309.SS,600332.SS,600346.SS,600362.SS,600372.SS,600377.SS,600406.SS,600415.SS,600426.SS,600436.SS,600438.SS,600460.SS,600482.SS,600489.SS,600515.SS,600519.SS,600547.SS,600570.SS,600584.SS,600585.SS,600588.SS,600600.SS,600660.SS,600674.SS,600690.SS,600741.SS,600745.SS,600760.SS,600795.SS,600803.SS,600809.SS,600837.SS,600845.SS,600875.SS,600886.SS,600887.SS,600893.SS,600900.SS,600905.SS,600918.SS,600919.SS,600926.SS,600938.SS,600941.SS,600958.SS,600989.SS,600999.SS,601006.SS,601009.SS,601012.SS,601021.SS,601059.SS,601066.SS,601088.SS,601100.SS,601111.SS,601117.SS,601127.SS,601136.SS,601138.SS,601166.SS,601169.SS,601186.SS,601211.SS,601225.SS,601229.SS,601236.SS,601238.SS,601288.SS,601318.SS,601319.SS,601328.SS,601336.SS,601360.SS,601377.SS,601390.SS,601398.SS,601600.SS,601601.SS,601607.SS,601618.SS,601628.SS,601633.SS,601658.SS,601668.SS,601669.SS,601688.SS,601689.SS,601698.SS,601699.SS,601728.SS,601766.SS,601788.SS,601799.SS,601800.SS,601808.SS,601816.SS,601818.SS,601838.SS,601857.SS,601865.SS,601868.SS,601872.SS,601877.SS,601878.SS,601881.SS,601888.SS,601898.SS,601899.SS,601901.SS,601916.SS,601919.SS,601939.SS,601985.SS,601988.SS,601989.SS,601995.SS,601998.SS,603019.SS,603195.SS,603259.SS,603260.SS,603288.SS,603296.SS,603369.SS,603392.SS,603501.SS,603659.SS,603799.SS,603806.SS,603833.SS,603986.SS,603993.SS,605117.SS,605499.SS,688008.SS,688009.SS,688012.SS,688036.SS,688041.SS,688082.SS,688111.SS,688126.SS,688169.SS,688187.SS,688223.SS,688256.SS,688271.SS,688303.SS,688396.SS,688472.SS,688506.SS,688599.SS,688981.SS"
    #A50
    #tickers = "000001.SZ,000002.SZ,000009.SZ,000034.SZ,000035.SZ,000039.SZ,000063.SZ,000066.SZ,000069.SZ,000100.SZ,000157.SZ,000301.SZ,000333.SZ,000338.SZ,000400.SZ,000408.SZ,000423.SZ,000425.SZ,000519.SZ,000538.SZ,000547.SZ,000568.SZ,000617.SZ,000623.SZ,000625.SZ,000629.SZ,000630.SZ,000651.SZ,000661.SZ,000683.SZ,000708.SZ,000725.SZ,000733.SZ,000738.SZ,000768.SZ,000786.SZ,000792.SZ,000807.SZ,000818.SZ,000830.SZ,000831.SZ,000858.SZ,000878.SZ,000887.SZ,000932.SZ,000933.SZ,000938.SZ,000960.SZ,000963.SZ,000967.SZ,000975.SZ,000977.SZ,000988.SZ,000998.SZ,000999.SZ,001914.SZ,001965.SZ,001979.SZ,002001.SZ,002007.SZ,002008.SZ,002025.SZ,002027.SZ,002028.SZ,002044.SZ,002049.SZ,002050.SZ,002064.SZ,002065.SZ,002074.SZ,002078.SZ,002081.SZ,002085.SZ,002091.SZ,002120.SZ,002128.SZ,002129.SZ,002131.SZ,002138.SZ,002145.SZ,002151.SZ,002152.SZ,002156.SZ,002176.SZ,002179.SZ,002180.SZ,002185.SZ,002195.SZ,002202.SZ,002223.SZ,002230.SZ,002236.SZ,002240.SZ,002241.SZ,002245.SZ,002252.SZ,002266.SZ,002268.SZ,002271.SZ,002273.SZ,002281.SZ,002292.SZ,002294.SZ,002312.SZ,002318.SZ,002340.SZ,002352.SZ,002353.SZ,002368.SZ,002371.SZ,002372.SZ,002384.SZ,002389.SZ,002405.SZ,002407.SZ,002409.SZ,002410.SZ,002414.SZ,002415.SZ,002422.SZ,002432.SZ,002436.SZ,002439.SZ,002444.SZ,002456.SZ,002459.SZ,002460.SZ,002463.SZ,002465.SZ,002466.SZ,002472.SZ,002475.SZ,002493.SZ,002497.SZ,002508.SZ,002517.SZ,002532.SZ,002541.SZ,002544.SZ,002555.SZ,002558.SZ,002572.SZ,002594.SZ,002601.SZ,002603.SZ,002607.SZ,002624.SZ,002625.SZ,002648.SZ,002709.SZ,002714.SZ,002738.SZ,002739.SZ,002756.SZ,002812.SZ,002821.SZ,002831.SZ,002841.SZ,002916.SZ,002920.SZ,002938.SZ,003816.SZ,300001.SZ,300002.SZ,300003.SZ,300012.SZ,300014.SZ,300015.SZ,300017.SZ,300024.SZ,300033.SZ,300037.SZ,300054.SZ,300058.SZ,300059.SZ,300068.SZ,300070.SZ,300073.SZ,300088.SZ,300114.SZ,300118.SZ,300122.SZ,300124.SZ,300136.SZ,300142.SZ,300144.SZ,300182.SZ,300207.SZ,300212.SZ,300223.SZ,300251.SZ,300253.SZ,300274.SZ,300285.SZ,300296.SZ,300308.SZ,300315.SZ,300316.SZ,300339.SZ,300346.SZ,300347.SZ,300383.SZ,300390.SZ,300394.SZ,300395.SZ,300408.SZ,300413.SZ,300418.SZ,300433.SZ,300438.SZ,300450.SZ,300454.SZ,300457.SZ,300459.SZ,300474.SZ,300476.SZ,300496.SZ,300502.SZ,300529.SZ,300558.SZ,300567.SZ,300568.SZ,300573.SZ,300595.SZ,300601.SZ,300604.SZ,300627.SZ,300628.SZ,300661.SZ,300676.SZ,300699.SZ,300724.SZ,300750.SZ,300751.SZ,300759.SZ,300760.SZ,300763.SZ,300769.SZ,300782.SZ,300832.SZ,300866.SZ,300896.SZ,300919.SZ,300999.SZ,301236.SZ,600000.SS,600004.SS,600007.SS,600008.SS,600009.SS,600010.SS,600011.SS,600018.SS,600019.SS,600026.SS,600027.SS,600028.SS,600029.SS,600030.SS,600031.SS,600036.SS,600038.SS,600039.SS,600048.SS,600050.SS,600066.SS,600085.SS,600089.SS,600096.SS,600104.SS,600111.SS,600115.SS,600118.SS,600129.SS,600131.SS,600141.SS,600143.SS,600150.SS,600153.SS,600160.SS,600161.SS,600166.SS,600167.SS,600170.SS,600176.SS,600177.SS,600183.SS,600188.SS,600196.SS,600219.SS,600233.SS,600256.SS,600258.SS,600276.SS,600309.SS,600315.SS,600316.SS,600323.SS,600325.SS,600332.SS,600335.SS,600346.SS,600352.SS,600362.SS,600372.SS,600392.SS,600398.SS,600399.SS,600406.SS,600415.SS,600418.SS,600426.SS,600436.SS,600438.SS,600460.SS,600482.SS,600486.SS,600487.SS,600489.SS,600497.SS,600498.SS,600499.SS,600515.SS,600516.SS,600519.SS,600521.SS,600529.SS,600535.SS,600547.SS,600549.SS,600563.SS,600570.SS,600584.SS,600585.SS,600588.SS,600637.SS,600655.SS,600660.SS,600667.SS,600674.SS,600690.SS,600699.SS,600704.SS,600741.SS,600745.SS,600754.SS,600755.SS,600760.SS,600763.SS,600765.SS,600771.SS,600795.SS,600803.SS,600816.SS,600820.SS,600839.SS,600845.SS,600859.SS,600862.SS,600867.SS,600879.SS,600884.SS,600885.SS,600886.SS,600887.SS,600893.SS,600895.SS,600900.SS,600905.SS,600919.SS,600938.SS,600941.SS,600988.SS,600989.SS,600998.SS,601000.SS,601006.SS,601012.SS,601018.SS,601021.SS,601058.SS,601088.SS,601100.SS,601111.SS,601117.SS,601127.SS,601155.SS,601166.SS,601168.SS,601179.SS,601186.SS,601216.SS,601225.SS,601233.SS,601238.SS,601288.SS,601318.SS,601319.SS,601328.SS,601360.SS,601390.SS,601398.SS,601567.SS,601600.SS,601601.SS,601607.SS,601615.SS,601618.SS,601628.SS,601633.SS,601636.SS,601658.SS,601668.SS,601669.SS,601677.SS,601689.SS,601727.SS,601728.SS,601766.SS,601799.SS,601800.SS,601816.SS,601857.SS,601866.SS,601868.SS,601872.SS,601877.SS,601880.SS,601888.SS,601899.SS,601919.SS,601966.SS,601985.SS,601988.SS,601989.SS,603000.SS,603019.SS,603077.SS,603087.SS,603129.SS,603259.SS,603260.SS,603288.SS,603290.SS,603392.SS,603456.SS,603486.SS,603501.SS,603568.SS,603588.SS,603596.SS,603605.SS,603606.SS,603613.SS,603650.SS,603659.SS,603688.SS,603799.SS,603806.SS,603816.SS,603833.SS,603882.SS,603885.SS,603899.SS,603939.SS,603979.SS,603986.SS,603993.SS,605117.SS,605358.SS,605499.SS,688002.SS,688005.SS,688008.SS,688009.SS,688012.SS,688036.SS,688041.SS,688047.SS,688063.SS,688072.SS,688099.SS,688111.SS,688120.SS,688122.SS,688126.SS,688169.SS,688180.SS,688188.SS,688223.SS,688235.SS,688256.SS,688271.SS,688303.SS,688390.SS,688396.SS,688599.SS,688617.SS,688777.SS,688981.SS"
    # ZZ 800
    tickers ="000001.SZ,000002.SZ,000009.SZ,000021.SZ,000027.SZ,000032.SZ,000034.SZ,000039.SZ,000050.SZ,000060.SZ,000063.SZ,000066.SZ,000100.SZ,000155.SZ,000157.SZ,000166.SZ,000301.SZ,000333.SZ,000338.SZ,000400.SZ,000401.SZ,000403.SZ,000408.SZ,000423.SZ,000425.SZ,000426.SZ,000513.SZ,000519.SZ,000537.SZ,000538.SZ,000539.SZ,000559.SZ,000563.SZ,000568.SZ,000591.SZ,000596.SZ,000598.SZ,000617.SZ,000623.SZ,000625.SZ,000629.SZ,000630.SZ,000636.SZ,000651.SZ,000661.SZ,000683.SZ,000703.SZ,000708.SZ,000709.SZ,000723.SZ,000725.SZ,000728.SZ,000729.SZ,000733.SZ,000738.SZ,000739.SZ,000750.SZ,000768.SZ,000776.SZ,000778.SZ,000783.SZ,000785.SZ,000786.SZ,000792.SZ,000800.SZ,000807.SZ,000818.SZ,000825.SZ,000830.SZ,000831.SZ,000858.SZ,000876.SZ,000878.SZ,000883.SZ,000887.SZ,000893.SZ,000895.SZ,000898.SZ,000921.SZ,000932.SZ,000937.SZ,000938.SZ,000958.SZ,000959.SZ,000960.SZ,000963.SZ,000967.SZ,000975.SZ,000977.SZ,000983.SZ,000987.SZ,000988.SZ,000997.SZ,000998.SZ,000999.SZ,001203.SZ,001227.SZ,001286.SZ,001289.SZ,001965.SZ,001979.SZ,002001.SZ,002007.SZ,002008.SZ,002019.SZ,002025.SZ,002027.SZ,002028.SZ,002044.SZ,002049.SZ,002050.SZ,002056.SZ,002064.SZ,002065.SZ,002074.SZ,002078.SZ,002080.SZ,002085.SZ,002120.SZ,002128.SZ,002129.SZ,002138.SZ,002142.SZ,002152.SZ,002153.SZ,002155.SZ,002156.SZ,002179.SZ,002180.SZ,002185.SZ,002195.SZ,002202.SZ,002203.SZ,002223.SZ,002230.SZ,002236.SZ,002240.SZ,002241.SZ,002244.SZ,002252.SZ,002261.SZ,002262.SZ,002266.SZ,002268.SZ,002271.SZ,002273.SZ,002281.SZ,002294.SZ,002299.SZ,002304.SZ,002311.SZ,002318.SZ,002340.SZ,002352.SZ,002353.SZ,002368.SZ,002371.SZ,002372.SZ,002373.SZ,002384.SZ,002385.SZ,002407.SZ,002408.SZ,002409.SZ,002410.SZ,002414.SZ,002415.SZ,002422.SZ,002423.SZ,002429.SZ,002430.SZ,002432.SZ,002436.SZ,002439.SZ,002444.SZ,002459.SZ,002460.SZ,002463.SZ,002465.SZ,002466.SZ,002472.SZ,002475.SZ,002487.SZ,002493.SZ,002500.SZ,002507.SZ,002508.SZ,002517.SZ,002531.SZ,002532.SZ,002555.SZ,002557.SZ,002558.SZ,002563.SZ,002568.SZ,002572.SZ,002594.SZ,002595.SZ,002601.SZ,002603.SZ,002607.SZ,002608.SZ,002624.SZ,002625.SZ,002648.SZ,002653.SZ,002670.SZ,002673.SZ,002683.SZ,002690.SZ,002709.SZ,002714.SZ,002736.SZ,002738.SZ,002739.SZ,002756.SZ,002797.SZ,002812.SZ,002821.SZ,002831.SZ,002841.SZ,002850.SZ,002867.SZ,002916.SZ,002920.SZ,002926.SZ,002938.SZ,002939.SZ,002945.SZ,002958.SZ,002966.SZ,002984.SZ,003022.SZ,003031.SZ,003035.SZ,003816.SZ,300001.SZ,300002.SZ,300003.SZ,300009.SZ,300012.SZ,300014.SZ,300015.SZ,300017.SZ,300024.SZ,300033.SZ,300037.SZ,300054.SZ,300058.SZ,300059.SZ,300070.SZ,300073.SZ,300114.SZ,300118.SZ,300122.SZ,300124.SZ,300136.SZ,300140.SZ,300142.SZ,300144.SZ,300146.SZ,300207.SZ,300212.SZ,300223.SZ,300251.SZ,300274.SZ,300285.SZ,300308.SZ,300316.SZ,300339.SZ,300347.SZ,300373.SZ,300383.SZ,300390.SZ,300394.SZ,300395.SZ,300408.SZ,300413.SZ,300418.SZ,300433.SZ,300442.SZ,300450.SZ,300474.SZ,300476.SZ,300487.SZ,300496.SZ,300498.SZ,300502.SZ,300529.SZ,300558.SZ,300567.SZ,300573.SZ,300595.SZ,300601.SZ,300604.SZ,300628.SZ,300661.SZ,300676.SZ,300677.SZ,300699.SZ,300724.SZ,300748.SZ,300750.SZ,300751.SZ,300759.SZ,300760.SZ,300763.SZ,300765.SZ,300782.SZ,300803.SZ,300832.SZ,300866.SZ,300888.SZ,300896.SZ,300919.SZ,300957.SZ,300979.SZ,300999.SZ,301165.SZ,301236.SZ,301267.SZ,301269.SZ,301301.SZ,301308.SZ,301358.SZ,301498.SZ,600000.SS,600004.SS,600007.SS,600008.SS,600009.SS,600010.SS,600011.SS,600015.SS,600016.SS,600018.SS,600019.SS,600021.SS,600023.SS,600025.SS,600026.SS,600027.SS,600028.SS,600029.SS,600030.SS,600031.SS,600032.SS,600036.SS,600038.SS,600039.SS,600048.SS,600050.SS,600056.SS,600060.SS,600061.SS,600062.SS,600066.SS,600079.SS,600085.SS,600089.SS,600095.SS,600096.SS,600098.SS,600104.SS,600109.SS,600111.SS,600115.SS,600118.SS,600126.SS,600129.SS,600131.SS,600132.SS,600141.SS,600143.SS,600150.SS,600153.SS,600155.SS,600157.SS,600160.SS,600161.SS,600166.SS,600170.SS,600176.SS,600177.SS,600183.SS,600188.SS,600196.SS,600208.SS,600219.SS,600233.SS,600258.SS,600271.SS,600276.SS,600282.SS,600295.SS,600298.SS,600299.SS,600309.SS,600312.SS,600316.SS,600325.SS,600329.SS,600332.SS,600339.SS,600346.SS,600348.SS,600350.SS,600352.SS,600361.SS,600362.SS,600369.SS,600372.SS,600373.SS,600377.SS,600378.SS,600380.SS,600390.SS,600392.SS,600398.SS,600406.SS,600415.SS,600416.SS,600418.SS,600426.SS,600435.SS,600436.SS,600438.SS,600460.SS,600482.SS,600483.SS,600486.SS,600487.SS,600489.SS,600497.SS,600498.SS,600499.SS,600500.SS,600511.SS,600515.SS,600516.SS,600517.SS,600519.SS,600521.SS,600528.SS,600529.SS,600535.SS,600536.SS,600546.SS,600547.SS,600549.SS,600563.SS,600566.SS,600570.SS,600578.SS,600580.SS,600582.SS,600583.SS,600584.SS,600585.SS,600588.SS,600598.SS,600600.SS,600606.SS,600612.SS,600637.SS,600642.SS,600655.SS,600660.SS,600663.SS,600673.SS,600674.SS,600685.SS,600688.SS,600690.SS,600699.SS,600704.SS,600707.SS,600720.SS,600737.SS,600739.SS,600741.SS,600745.SS,600754.SS,600755.SS,600760.SS,600763.SS,600764.SS,600765.SS,600795.SS,600801.SS,600803.SS,600808.SS,600809.SS,600816.SS,600820.SS,600837.SS,600839.SS,600845.SS,600848.SS,600859.SS,600862.SS,600863.SS,600867.SS,600871.SS,600872.SS,600873.SS,600875.SS,600879.SS,600884.SS,600885.SS,600886.SS,600887.SS,600893.SS,600895.SS,600900.SS,600901.SS,600905.SS,600906.SS,600909.SS,600918.SS,600919.SS,600925.SS,600926.SS,600927.SS,600928.SS,600938.SS,600941.SS,600956.SS,600958.SS,600959.SS,600968.SS,600970.SS,600977.SS,600988.SS,600989.SS,600995.SS,600998.SS,600999.SS,601000.SS,601001.SS,601006.SS,601009.SS,601012.SS,601016.SS,601019.SS,601021.SS,601059.SS,601061.SS,601066.SS,601088.SS,601098.SS,601099.SS,601100.SS,601106.SS,601108.SS,601111.SS,601117.SS,601118.SS,601127.SS,601128.SS,601136.SS,601138.SS,601139.SS,601155.SS,601156.SS,601158.SS,601162.SS,601166.SS,601168.SS,601169.SS,601179.SS,601186.SS,601198.SS,601211.SS,601212.SS,601216.SS,601225.SS,601228.SS,601229.SS,601231.SS,601233.SS,601236.SS,601238.SS,601288.SS,601318.SS,601319.SS,601328.SS,601336.SS,601360.SS,601377.SS,601390.SS,601398.SS,601399.SS,601456.SS,601555.SS,601567.SS,601568.SS,601577.SS,601598.SS,601600.SS,601601.SS,601607.SS,601608.SS,601611.SS,601615.SS,601618.SS,601628.SS,601633.SS,601636.SS,601658.SS,601665.SS,601666.SS,601668.SS,601669.SS,601688.SS,601689.SS,601696.SS,601698.SS,601699.SS,601717.SS,601728.SS,601766.SS,601788.SS,601799.SS,601800.SS,601808.SS,601816.SS,601818.SS,601838.SS,601857.SS,601858.SS,601865.SS,601866.SS,601868.SS,601872.SS,601877.SS,601878.SS,601880.SS,601881.SS,601888.SS,601898.SS,601899.SS,601901.SS,601916.SS,601918.SS,601919.SS,601928.SS,601933.SS,601939.SS,601958.SS,601965.SS,601966.SS,601985.SS,601988.SS,601989.SS,601990.SS,601991.SS,601992.SS,601995.SS,601997.SS,601998.SS,603000.SS,603019.SS,603056.SS,603077.SS,603087.SS,603129.SS,603156.SS,603160.SS,603179.SS,603185.SS,603195.SS,603225.SS,603228.SS,603233.SS,603259.SS,603260.SS,603288.SS,603290.SS,603296.SS,603298.SS,603338.SS,603341.SS,603345.SS,603369.SS,603379.SS,603392.SS,603444.SS,603456.SS,603486.SS,603501.SS,603529.SS,603556.SS,603568.SS,603589.SS,603596.SS,603605.SS,603606.SS,603650.SS,603658.SS,603659.SS,603688.SS,603707.SS,603712.SS,603728.SS,603737.SS,603786.SS,603799.SS,603806.SS,603816.SS,603826.SS,603833.SS,603858.SS,603868.SS,603882.SS,603883.SS,603885.SS,603893.SS,603899.SS,603927.SS,603939.SS,603979.SS,603986.SS,603993.SS,605117.SS,605358.SS,605499.SS,688002.SS,688005.SS,688008.SS,688009.SS,688012.SS,688017.SS,688032.SS,688036.SS,688041.SS,688047.SS,688052.SS,688065.SS,688072.SS,688082.SS,688099.SS,688111.SS,688114.SS,688120.SS,688122.SS,688126.SS,688153.SS,688169.SS,688172.SS,688180.SS,688187.SS,688188.SS,688213.SS,688220.SS,688223.SS,688234.SS,688248.SS,688249.SS,688256.SS,688271.SS,688276.SS,688278.SS,688281.SS,688295.SS,688297.SS,688301.SS,688303.SS,688331.SS,688349.SS,688361.SS,688363.SS,688375.SS,688385.SS,688387.SS,688390.SS,688396.SS,688425.SS,688469.SS,688472.SS,688475.SS,688506.SS,688516.SS,688520.SS,688521.SS,688525.SS,688536.SS,688538.SS,688561.SS,688563.SS,688567.SS,688578.SS,688599.SS,688617.SS,688772.SS,688777.SS,688778.SS,688819.SS,688981.SS,689009.SS"
    tickers =tickers.upper()
    tickers = tickers.split(",")
    #tickers = ["AAPL", "MSFT", "GOOG", "AMZN", "TSLA"]
    start_date = "2024-01-01"
    end_date = "2024-12-27"
    
    # Prepare dataset
    features, target, dates, data = prepare_dataset(tickers, start_date, end_date)
    scaler = MinMaxScaler()
    features = scaler.fit_transform(features)  # Scale features
    target = scaler.fit_transform(target)  # Scale targets

    # Split data without shuffling (so that the order is preserved)
    X_train, X_test, y_train, y_test, dates_train, dates_test = train_test_split(features, target, dates[1:], test_size=0.4, shuffle=False)

    #checkpoint_path = "training/best.keras"
    checkpoint_path = "/mnt/d/PriProjects/EloStock/best_model.keras"
    training(checkpoint_path)
    best_model = tf.keras.models.load_model(checkpoint_path)

    # Test the model
    test_loss, test_mae = best_model.evaluate(X_test, y_test)
    print(f"\nTest Loss: {test_loss:.4f}, Test MAE: {test_mae:.4f}")
    
    # Predict Elo ratings for test data
    predictions = best_model.predict(X_test)
    
    # Simulate trading with $10,000 for top 2 stocks and equal split across all stocks
    initial_investment = 10000
    portfolio_value_top_2 = initial_investment
    portfolio_value_equal = initial_investment
    last_top_2 = None
    top_2_tickers = []

    portfolio_values_top_2 = [portfolio_value_top_2]  # Store portfolio value for top 2 stocks
    portfolio_values_equal = [portfolio_value_equal]  # Store portfolio value for equal split

    # Fetch daily returns for simulation from original data (not predictions)
    for j in range(len(dates_test) - 1):  # Loop until the second last date
        predicted_elo = predictions[j]
        tickers_elo = list(zip(tickers, predicted_elo))  # Combine tickers with predicted Elo
        tickers_elo.sort(key=lambda x: x[1], reverse=True)  # Sort by Elo rating in descending order
        
        top_2_today = tickers_elo[:2]  # Get the top 2 tickers
        
        # Update only if top 2 tickers change
        if top_2_today != last_top_2:
            last_top_2 = top_2_today
        
        stock_1 = top_2_today[0][0]
        stock_2 = top_2_today[1][0]
        
        # Get next day's returns for top 2 stocks
        try:
            next_day_return_1 = (data[stock_1].iloc[j + 1] / data[stock_1].iloc[j]) - 1
            next_day_return_2 = (data[stock_2].iloc[j + 1] / data[stock_2].iloc[j]) - 1
        except IndexError:
            continue  # Skip if next day's data is not available
        
        # Update portfolio based on next day's returns for top 2 stocks
        allocation_per_stock = portfolio_value_top_2 / 2  # Equal split between top 2 stocks
        portfolio_value_top_2 += allocation_per_stock * next_day_return_1 + allocation_per_stock * next_day_return_2
        
        # Simulate the portfolio with equal split across all stocks
        allocation_per_stock_equal = portfolio_value_equal / len(tickers)  # Equal split across all stocks
        for stock in tickers:
            try:
                next_day_return = (data[stock].iloc[j + 1] / data[stock].iloc[j]) - 1
                portfolio_value_equal += allocation_per_stock_equal * next_day_return
            except IndexError:
                continue  # Skip if next day's data is not available
        
        # Store the portfolio values for plotting
        portfolio_values_top_2.append(portfolio_value_top_2)
        portfolio_values_equal.append(portfolio_value_equal)
        
        # Print results for the day
        print(f"\nDate: {dates_test[j]}")
        print(f"Top 2 Stocks: {stock_1}, {stock_2}")
        print(f"Portfolio Value (Top 2 Stocks): ${portfolio_value_top_2:.2f}")
        print(f"Portfolio Value (Equal Split): ${portfolio_value_equal:.2f}")
    
    print(f"\nFinal Portfolio Value (Top 2 Stocks): ${portfolio_value_top_2:.2f}")
    print(f"Final Portfolio Value (Equal Split): ${portfolio_value_equal:.2f}")

    # Saving the plot
    plt.figure(figsize=(12, 6))
    plt.plot(dates_test[:-1], portfolio_values_top_2[1:], label="Top 2 Stocks Portfolio", color='b', linewidth=2)
    plt.plot(dates_test[:-1], portfolio_values_equal[1:], label="Equal Split Portfolio", color='g', linewidth=2)
    plt.title('Portfolio Value Over Time')
    plt.xlabel('Date')
    plt.ylabel('Portfolio Value (USD)')
    plt.legend()
    plt.grid(True)
    plt.savefig('/mnt/d/PriProjects/EloStock/portfolio_simulation_updated.png')  # Save plot as a PNG file
    print("Plot saved as 'portfolio_simulation_updated.png'.")